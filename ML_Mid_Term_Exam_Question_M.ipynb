{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaho0/Aaagh-more-math/blob/main/ML_Mid_Term_Exam_Question_M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba7b32d",
      "metadata": {
        "id": "fba7b32d"
      },
      "source": [
        "ML – MIDTERM EXAM (100 Marks)\n",
        "\n",
        "This notebook is your **single submission file** for the Midterm.\n",
        "\n",
        "- **Total marks:** 100  \n",
        "  - Section A: 40 marks  \n",
        "  - Section B: 60 marks  \n",
        "- Answer **all questions** in this notebook.  \n",
        "- Do **not** create a separate PDF.  \n",
        "- Use clear headings, code, and explanations.\n",
        "\n",
        "- Run all cells before submitting so all outputs are visible.\n",
        "- Set the Colab file's shareable link to ‘Anyone with the link’ and ‘View’ access, then submit it in the Phitron Assignment module's Assignment submission section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2c0a54c6",
      "metadata": {
        "id": "2c0a54c6"
      },
      "outputs": [],
      "source": [
        "# Common imports for Section B (run once)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (6, 4)\n",
        "plt.rcParams['axes.grid'] = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f22f0e79",
      "metadata": {
        "id": "f22f0e79"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION A – Short Application Questions (40 Marks)\n",
        "\n",
        "Write your answers in the provided **answer cells** in this notebook. Use text, formulas, and short reasoning.\n",
        "\n",
        "Marks for each question are clearly mentioned.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "845c66f1",
      "metadata": {
        "id": "845c66f1"
      },
      "source": [
        "### Q1. Descriptive Statistics and Distributions (15 marks)\n",
        "\n",
        "A dataset of monthly customer spending (in dollars) is:\n",
        "\n",
        "`[30, 35, 32, 34, 33, 500, 31, 34, 32, 33]`\n",
        "\n",
        "1. Compute the **median** and **IQR**. Show your working clearly.  \n",
        "2. Use the **IQR rule** to check if 500 is an outlier. Show your steps and the fences.  \n",
        "3. Explain in 3 to 5 sentences why **median + IQR** may be better than **mean + standard deviation** for this dataset.\n",
        "\n",
        "Write your full answer in the cell below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "005abbd0",
      "metadata": {
        "id": "005abbd0"
      },
      "source": [
        "#### Q1 Answer (Student)\n",
        "\n",
        "_Write your calculations and explanation here. You may use Python below if you want, but final reasoning must be readable._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e59611ba",
      "metadata": {
        "id": "e59611ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7b7fdf-701d-432e-9d44-5e1424478726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median: 33.0\n",
            "IQR: 2.0\n",
            "Outliers: [500]\n",
            "Mean: 79.4\n",
            "Standard Deviation: 140.2071324861899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30, 31, 32, 32, 33, 33, 34, 34, 35, 500]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Optional helper code for Q1 (not required)\n",
        "data_q1 = [30, 35, 32, 34, 33, 500, 31, 34, 32, 33]\n",
        "data_q1.sort()\n",
        "arr_q1=np.array(data_q1)\n",
        "median=np.median(arr_q1)\n",
        "mean=np.mean(arr_q1)\n",
        "std=np.std(arr_q1)\n",
        "Q1=np.percentile(arr_q1,25)\n",
        "Q3=np.percentile(arr_q1,75)\n",
        "IQR=Q3-Q1\n",
        "lower_Fence=Q1-1.5*IQR\n",
        "upper_fence=Q1+1.5*IQR\n",
        "outliers=arr_q1[(arr_q1<lower_Fence)|(arr_q1>upper_fence)]\n",
        "print(\"Median:\",median)\n",
        "print(\"IQR:\",IQR)\n",
        "print(\"Outliers:\",outliers)\n",
        "print(\"Mean:\",mean)\n",
        "print(\"Standard Deviation:\",std)\n",
        "data_q1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1 Answer**\n",
        "Mean and standard deviation are affected by extreme outliers,in this case all spending is between 30-35,500 is extreme outlier,this makes mean go far away ,median  shows the middle value,median is not affected by 500,because it just takes center position.IQR also ignores outliers,it only looks at middle 50% data.Here median and IQR will predict better than mean and std"
      ],
      "metadata": {
        "id": "T5SbPqBYiRtH"
      },
      "id": "T5SbPqBYiRtH"
    },
    {
      "cell_type": "markdown",
      "id": "df522116",
      "metadata": {
        "id": "df522116"
      },
      "source": [
        "### Q2. Bayes and Probability in ML (10 marks)\n",
        "\n",
        "A disease affects **1 percent** of people.  \n",
        "A test has:  \n",
        "- Sensitivity: **90 percent**  \n",
        "- Specificity: **92 percent**  \n",
        "\n",
        "A random person tests positive.\n",
        "\n",
        "1. Compute the **positive predictive value (PPV)** using Bayes theorem. Show all steps with probabilities.  \n",
        "2. If prevalence rises to **20 percent**, explain in 3 to 4 sentences whether PPV increases or decreases and why. You may refer to the Bayes formula in words.\n",
        "\n",
        "Write your full answer in the cell below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0cebe10",
      "metadata": {
        "id": "e0cebe10"
      },
      "source": [
        "#### Q2 Answer\n",
        "\n",
        "Probability of disease P(D)=1%=0.01\n",
        "Probability of No Disease P(-D)=1-0.01=0.99\n",
        "Sensitivity=True Positive Rate P(+|D)=90%=0.90\n",
        "Specificity=True Negative Rate P(-|-D)=92%=0.92\n",
        "\n",
        "False Positive Rate=P(+|-D)=1-Specificity=1-0.92=0.08\n",
        "\n",
        "Bayes,P(D|+)= (P(+|D)xP(D))/P(+)\n",
        "\n",
        "Now,P(+)=[P(+|D)xP(D)]+[P(+|-D)*P(-D)]\n",
        "\n",
        "p(+)=0.0882\n",
        "\n",
        "PPV=(P(+|D)xP(D))/P(+)\n",
        "so,PPV=10.2%\n",
        "Numerator = 0.90x0.20 = 0.18\n",
        "False positive = 0.08x0.80 = 0.064\n",
        "Denominator=0.18x0.064 =0.244\n",
        "\n",
        "PPV = 0.18 / 0.244 =73.8%\n",
        "\n",
        "*When disease is more common, PPV becomes bigger. Because now more people are already sick. So positive test is more true. False positive becomes less important. That is why PPV increases.*"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad2227dd",
      "metadata": {
        "id": "ad2227dd"
      },
      "source": [
        "### Q3. ML Pipeline Thinking (15 marks)\n",
        "\n",
        "Columns in a new dataset:\n",
        "\n",
        "- `age` (numeric)  \n",
        "- `region` (categorical with 7 levels)  \n",
        "- `daily_clicks` (numeric)  \n",
        "- `premium_user` (0 or 1 target)\n",
        "\n",
        "1. Identify the **type of ML task**. (1 or 2 lines)  \n",
        "2. List **four preprocessing steps** that would be reasonable for this dataset. (bullet points are fine)  \n",
        "3. In one short paragraph (6 to 8 sentences), describe the **end to end ML pipeline** you would follow for this problem, from raw data to model evaluation.\n",
        "\n",
        "Write your full answer in the cell below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7a3ead6",
      "metadata": {
        "id": "a7a3ead6"
      },
      "source": [
        "#### Q3 Answer (Student)\n",
        "\n",
        "1.This is a binary classification problem,the target premium_user has two values: 0 or 1.\n",
        "\n",
        "2.*Four Preprocessing Steps*:\n",
        "\n",
        "* Handle missing values\n",
        "\n",
        "* Encode the categorical feature region (using one-hot encoding)\n",
        "\n",
        "* Scale numeric features like age and daily_clicks.\n",
        "\n",
        "* Check and handle outliers in daily_clicks\n",
        "\n",
        "3.Firstly dataset is checked is there any missing values available,then missing values are handles.Incase of outliers they are also scaled by any scaler for example: robust,minmax or any scaler.And in case of categorical column it is encoded by preferable encoder.After encoding they are splited into train and test data and a suitable classification model is used to train the data,after training model is tested by test dataset.Then performence is measured using accuracy,precision,recall,f1 score and confusion matrix.Finally the best model is selected for prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26ac9d44",
      "metadata": {
        "id": "26ac9d44"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION B – Applied Coding Problems (60 Marks)\n",
        "\n",
        "Answer **all three questions** in this section.\n",
        "\n",
        "- Write clean, commented code.  \n",
        "- After each main step, add a short markdown explanation of what you did and what you observe.  \n",
        "- Make sure all plots are visible in the notebook.\n",
        "\n",
        "Marks for each question are clearly mentioned.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "831e60e5",
      "metadata": {
        "id": "831e60e5"
      },
      "source": [
        "### Q4. Applied EDA and Preprocessing (20 marks)\n",
        "\n",
        "We work with the following dataset:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"age\": [25, 30, None, 22, 45, 52, None],\n",
        "    \"region\": [\"north\",\"south\",\"north\",\"east\",\"west\",\"west\",\"south\"],\n",
        "    \"purchases\": [3, 10, 5, None, 20, 18, 9],\n",
        "    \"premium_user\": [0,1,0,0,1,1,0]\n",
        "})\n",
        "```\n",
        "\n",
        "**Tasks (20 marks total):**\n",
        "\n",
        "1. **Compact EDA using pandas** (6 marks)  \n",
        "   - Show missing value summary for each column.  \n",
        "   - Show number of unique values per column.  \n",
        "   - Show correlation among numeric columns.  \n",
        "   - Plot:  \n",
        "     - A histogram of `purchases`.  \n",
        "     - A bar chart for `region` frequency.\n",
        "\n",
        "2. **Preprocess the dataset using sklearn plus pandas** (9 marks)  \n",
        "   - Impute `age` with **median**.  \n",
        "   - Impute `purchases` with **mean**.  \n",
        "   - One hot encode `region`.  \n",
        "   - Scale all numeric columns using **RobustScaler**.\n",
        "\n",
        "3. **Create one domain driven feature** (3 marks)  \n",
        "   - Example ideas: `high_spender` based on `purchases`, or `age_group` bins, or an interaction like `age * purchases`.\n",
        "\n",
        "4. Show the **final transformed dataframe** ready for model training. (2 marks)\n",
        "\n",
        "Use short explanations in markdown to describe each main block of code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4145df0b",
      "metadata": {
        "id": "4145df0b"
      },
      "outputs": [],
      "source": [
        "# Q4 – Student Answer\n",
        "\n",
        "# Step 1: Create the dataframe\n",
        "df = pd.DataFrame({\n",
        "    \"age\": [25, 30, None, 22, 45, 52, None],\n",
        "    \"region\": [\"north\",\"south\",\"north\",\"east\",\"west\",\"west\",\"south\"],\n",
        "    \"purchases\": [3, 10, 5, None, 20, 18, 9],\n",
        "    \"premium_user\": [0,1,0,0,1,1,0]\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c009f9e",
      "metadata": {
        "id": "3c009f9e"
      },
      "source": [
        "_Use additional code cells below for EDA, preprocessing, feature engineering, and final dataframe. Add brief explanations in markdown between code blocks._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5fba25",
      "metadata": {
        "id": "6b5fba25"
      },
      "source": [
        "---\n",
        "\n",
        "### Q5. Applied Regression and Residual Analysis (20 marks)\n",
        "\n",
        "We use this dataset:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    \"area_sqft\": [800, 1000, 1200, 1500, 1800, 2000],\n",
        "    \"bedrooms\": [2,2,3,3,4,4],\n",
        "    \"price\": [120, 150, 170, 210, 260, 300]\n",
        "})\n",
        "```\n",
        "\n",
        "**Tasks (20 marks total):**\n",
        "\n",
        "1. Create the dataframe `df2`. (1 mark)  \n",
        "2. Split the data into **train and test** with 80 percent train and 20 percent test. (3 marks)  \n",
        "3. Fit a **LinearRegression** model to predict `price` from `area_sqft` and `bedrooms`. (4 marks)  \n",
        "4. Print model **intercept**, **coefficients**, and **predictions** on the test set. (4 marks)  \n",
        "5. Compute the following metrics on the test set. (6 marks)  \n",
        "   - Mean Absolute Error (MAE)  \n",
        "   - Root Mean Squared Error (RMSE)  \n",
        "   - R squared (R²)  \n",
        "6. Plot a **residual plot** with `y_true − y_pred` on the vertical axis and `y_pred` on the horizontal axis. (2 marks)  \n",
        "   - Add a short note explaining what you observe from the residuals.\n",
        "\n",
        "Again, use short markdown explanations to describe each step.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8644403a",
      "metadata": {
        "id": "8644403a"
      },
      "outputs": [],
      "source": [
        "# Q5 – Student Answer\n",
        "\n",
        "# Step 1: Create the dataframe\n",
        "df2 = pd.DataFrame({\n",
        "    \"area_sqft\": [800, 1000, 1200, 1500, 1800, 2000],\n",
        "    \"bedrooms\": [2,2,3,3,4,4],\n",
        "    \"price\": [120, 150, 170, 210, 260, 300]\n",
        "})\n",
        "\n",
        "df2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d24b23",
      "metadata": {
        "id": "58d24b23"
      },
      "source": [
        "_Use additional code cells below for train test split, model training, metrics, and the residual plot. Add a brief comment on the residuals in markdown._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ee915fd",
      "metadata": {
        "id": "7ee915fd"
      },
      "source": [
        "---\n",
        "\n",
        "### Q6. Applied Classification, Metrics, Trees and ROC (20 marks)\n",
        "\n",
        "We start with:\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "y_true = np.array([1,0,1,0,1,0,1,0,1,0])\n",
        "y_prob = np.array([0.9,0.1,0.85,0.2,0.7,0.4,0.6,0.3,0.95,0.05])\n",
        "```\n",
        "\n",
        "**Part 1: Threshold based classification and metrics (8 marks)**\n",
        "\n",
        "1. With threshold **0.5**, convert probabilities to class predictions. Then compute:  \n",
        "   - Confusion matrix  \n",
        "   - Precision  \n",
        "   - Recall  \n",
        "   - F1 score\n",
        "\n",
        "2. With threshold **0.3**, convert probabilities to class predictions again and recompute the same metrics.\n",
        "\n",
        "3. In 3 to 4 sentences, explain how lowering the threshold from 0.5 to 0.3 changed precision and recall and why this happens.\n",
        "\n",
        "**Part 2: ROC and AUC (6 marks)**\n",
        "\n",
        "4. Plot the **ROC curve** using `y_true` and `y_prob`.  \n",
        "5. Compute the **AUC** and print it with 3 decimal places.  \n",
        "6. Add a one or two line comment on what a high or low AUC means in this context.\n",
        "\n",
        "**Part 3: Decision Tree on a small dataset (6 marks)**\n",
        "\n",
        "Create this dataset:\n",
        "\n",
        "```python\n",
        "df3 = pd.DataFrame({\n",
        "    \"hours\": [1,2,3,4,5,1,2,3,4,5],\n",
        "    \"passed\": [0,0,0,1,1,0,0,1,1,1]\n",
        "})\n",
        "```\n",
        "\n",
        "7. Fit a `DecisionTreeClassifier(max_depth=2)` to predict `passed` from `hours`.  \n",
        "8. Plot the tree using `plot_tree`.  \n",
        "9. Write 2 to 3 lines explaining whether the tree looks like it might **overfit** or **generalize well**, given the dataset size and the model depth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2047a9f",
      "metadata": {
        "id": "e2047a9f"
      },
      "outputs": [],
      "source": [
        "# Q6 – Student Answer\n",
        "\n",
        "# Part 1: threshold based classification\n",
        "y_true = np.array([1,0,1,0,1,0,1,0,1,0])\n",
        "y_prob = np.array([0.9,0.1,0.85,0.2,0.7,0.4,0.6,0.3,0.95,0.05])\n",
        "\n",
        "# Write your code for threshold 0.5 and 0.3 below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70709ff1",
      "metadata": {
        "id": "70709ff1"
      },
      "source": [
        "_Add more code cells for ROC and AUC, and for the decision tree on df3. Write your short explanations in markdown after the relevant outputs._"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}